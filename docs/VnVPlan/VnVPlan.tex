\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{float}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}
\input{../Comments}
\input{../Common}
\usepackage{enumitem}
\usepackage{adjustbox}
\usepackage{longtable}
\usepackage{geometry}
\usepackage{pdflscape}
\usepackage{everypage}
\usepackage{lipsum}

\newcommand{\Lpagenumber}{\ifdim\textwidth=\linewidth\else\bgroup
  \dimendef\margin=0 %use \margin instead of \dimen0
  \ifodd\value{page}\margin=\oddsidemargin
  \else\margin=\evensidemargin
  \fi
  \raisebox{\dimexpr -\topmargin-\headheight-\headsep-0.5\linewidth}[0pt][0pt]{%
    \rlap{\hspace{\dimexpr \margin+\textheight+\footskip}%
    \llap{\rotatebox{90}{\thepage}}}}%
\egroup\fi}
\AddEverypageHook{\Lpagenumber}%

\begin{document}

\title{System Verification and Validation Plan for \progname{}} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Nov 3, 2023 & 1.0 & Initial Draft\\
April 2, 2024 & 2.0 & Final Version\\
\bottomrule
\end{tabularx}

~\\

\newpage

\tableofcontents

\listoftables


\newpage

\section{Symbols, Abbreviations, and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
      UI & User Interface \\
      ML & Machine Learning\\
      API & Application Programming Interface\\
      HTTP & Hypertext Transfer Protocol\\
      PDF & Portable Document Format\\
      .csv & Comma-Separated Values \\
      .txt & Text file\\
  \bottomrule
  
\end{tabular}\\


\newpage

\pagenumbering{arabic}

This document outlines the Verification and Validation (V\&V) plan for the MacONE project developed by Team \#5, Overwatch League. The V\&V plan is a critical component of our project management and quality assurance processes, ensuring that MacONE not only meets its specified requirements but also fulfills the needs and expectations of its users and stakeholders.

\paragraph{Roadmap}
The V\&V plan is structured as follows:
\begin{enumerate}
    \item \textbf{Symbols, Abbreviations, and Acronyms}
    \item \textbf{General Information}
    \item \textbf{Plan} 
    \item \textbf{System Test Description} 
    \item \textbf{Unit Test Description}
\end{enumerate}
\section{General Information}

\subsection{Summary}
MacONE is a tailored online platform aimed at streamlining and enhancing
the McMaster student experience. It enables students to directly extract and
integrate course information into their schedules, creating an individualized
to-do list. Additionally, MacONE provides easy access to vital university
resources, a forum for student interaction, a Pomodoro timer for effective
study sessions, a feedback box for users to share their insights directly with
developers, and a function allowing students to calculate their cumulative
GPA by uploading their transcripts, all designed to simplify student life at
McMaster University.


\subsection{Objectives}
This VnV plan would direct us through the testing process to ensure that our system would accomplish all the intended functions correctly and efficiently.  
Adequate tests would be planned according to functional and non-functional requirements stated in our SRS to ensure our project exhibits adequate qualities and functions.
We would prioritize and polish core functions including PDF unloading and analysis, integration between task management and Pomodoro, and those associated non-functional requirements. If time allows, we would also aim to develop tests for AI attention detection and the social component.


\subsection{Relevant Documentation}
\subsubsection{Development plan}
As part of the development process, the writing of this VnV plan implementation of all the test cases shall follow the development process specified in the development plan.

\subsubsection{SRS}
The functional and non-functional requirements and their corresponding fit criteria would lead the test plan and be used as a guideline to make sure tests could cover all the documented requirements.
\subsubsection{Hazard Analysis}
Additional requirements related to software failures should also be covered in testing.
\subsubsection{VnV Report}
The result from executing this VnV plan would be recorded in the VnV report.  The VnV plan could be revised from the results.
\section{Plan}

This section outlines the comprehensive strategy for verifying and validating the MacONE software, ensuring it aligns with specified requirements and design standards. The plan spans from team roles in verification to the utilization of various testing and verification tools.

\subsection{Verification and Validation Team}
     \begin{table}[H]
     \centering
     \begin{tabular}{l p{10cm}}
          \toprule
          \textbf{Name} & \textbf{Role and Specific Duties}\\
          \midrule
          Jinyao Qin & \textbf{Lead Verifier}: Oversees the entire process, coordinates with other team members, and ensures all verification steps are followed diligently.\\
          
          Qianni Wang & \textbf{Implementation Specialist}: Reviews the codebase to ensure it aligns with the documented requirements, also verifies the code's functionality, performance, and security aspects.\\
          
          Qiang Gao & \textbf{Implementation Specialist}: same as Qianni Wang\\
          
          Chenwei Song & \textbf{Manual Test Engineer}: Responsible for manual test cases, ensuring that all tests run in different environments, and reporting the results in an understandable format for the team.\\
          
          Shuting Shi & \textbf{Test Automation Engineer}: Responsible for automating test cases, ensuring that all tests run in different environments, and reporting the results in an understandable format for the team.\\
          \bottomrule
        \end{tabular}
     \caption{Verification and Validation Team Members and Their Roles}
     \end{table}

\subsection{SRS Verification Plan}

For the verification of the Software Requirements Specification (SRS) document, the following approaches will be adopted:

\begin{enumerate}
    \item \textbf{Peer Review:} The SRS will be reviewed by team members and classmates to identify any inconsistencies, ambiguities, or missing requirements.
    \item \textbf{Expert Review:} Experts in software development will be consulted to ensure the requirements are complete and feasible.
    \item \textbf{Supervisor Review:} The SRS will be reviewed by our supervisor, who can provide valuable insights from a strategic and technical perspective.
    \item \textbf{Client Feedback:} The document will be shared with the client or stakeholders for their feedback, ensuring alignment with their expectations and needs.
    \item \textbf{Automated Analysis Tools:} Tools such as requirement management software will be used for tracing and managing requirements systematically.
\end{enumerate}

Additionally, an SRS checklist will be utilized to systematically verify the content of the SRS document:
Please see our \href{https://github.com/wangq131/4G06CapstoneProjectT5/blob/main/docs/SRS/SRS.pdf#page=2}{SRS.pdf} for more details.


\subsection{Design Verification Plan}

The design verification for our project will focus on ensuring that the design is user-friendly, intuitive, and aligns with the architectural requirements specified in the SRS. The verification plan will include the following key activities:

\begin{enumerate}
    \item \textbf{Peer Reviews:} The design documents and models will be reviewed by team members and classmates to critique and provide feedback on the design's usability, intuitiveness, and adherence to architectural requirements.
    \item \textbf{Supervisor Review:} The design will be presented to the project supervisor for a thorough review, focusing on adherence to technical specifications and project objectives.
    \item \textbf{Design Walkthroughs:} Scheduled sessions where the design team presents the design to the stakeholders, including peers and supervisors, for feedback and suggestions.
    \item \textbf{Prototype Testing:} Early versions of the design will be tested to gather quick feedback on the design's effectiveness and user experience.
    \item \textbf{Consistency Check:} Ensuring that the design remains consistent with the requirements and objectives outlined in the SRS document.
\end{enumerate}

To comprehensively verify the design, the following checklist will be used:

\begin{enumerate}
    \item \textbf{Design Documentation Review:}
    \begin{itemize}
        \item Check if the design documentation is complete and clearly describes the architecture, components, and interfaces.
        \item Ensure that the design aligns with the project's objectives and requirements specified in the SRS.
    \end{itemize}
    
    \item \textbf{User Interface (UI) and User Experience (UX) Evaluation:}
    \begin{itemize}
        \item Verify that the UI design is intuitive and user-friendly.
        \item Ensure UI consistency across different parts of the application.
        \item Assess the UX for compliance with common usability standards and practices.
    \end{itemize}

    \item \textbf{Architectural Conformity:}
    \begin{itemize}
        \item Confirm that the system architecture supports all the required functionalities.
        \item Check for scalability, maintainability, and flexibility of the design.
    \end{itemize}

    \item \textbf{Performance and Security Review:}
    \begin{itemize}
        \item Ensure that the design incorporates adequate performance optimizations.
        \item Review the design for potential security vulnerabilities and data protection measures.
    \end{itemize}

    \item \textbf{Compliance with Standards:}
    \begin{itemize}
        \item Verify adherence to relevant industry and design standards.
    \end{itemize}

    \item \textbf{Feedback Integration:}
    \begin{itemize}
        \item Check that feedback from previous reviews (by classmates, peers, or stakeholders) has been adequately incorporated into the design.
    \end{itemize}
\end{enumerate}


\subsection{Verification and Validation Plan Verification Plan}

The verification and validation (V\&V) plan for our project includes ensuring the integrity and effectiveness of the V\&V processes themselves. Given the importance of this plan in the overall project quality assurance, the following approaches will be employed:

\begin{enumerate}
    \item \textbf{Peer Review:} The V\&V plan will be reviewed by team members and classmates to identify any omissions or areas needing improvement.
    \item \textbf{Mutation Testing:} This technique will be applied to evaluate the ability of our test cases to detect faults deliberately injected into the code.
    \item \textbf{Iterative Feedback Incorporation:} Feedback from all review sessions and testing phases will be systematically incorporated to refine the V\&V plan.
\end{enumerate}

To systematically verify the V\&V plan, the following checklist will be used:

\begin{itemize}
    \item Is the plan comprehensive, covering all aspects of software verification and validation?
    \item Are the responsibilities and roles in the V\&V process clearly defined?
    \item Does the plan include a variety of testing methods (e.g., unit testing, integration testing, system testing)?
    \item Is there a clear process for incorporating feedback and continuous improvement in the V\&V process?
    \item Are there criteria defined for the success of each testing phase?
    \item Is mutation testing included to assess the thoroughness of the test cases?
    \item Are there measures in place to track and resolve any identified issues during the V\&V process?
    \item Does the plan align with the project's schedule, resources, and constraints?
\end{itemize}

\subsection{Implementation Verification Plan}

The Implementation Verification Plan will ensure that the software implementation adheres to the requirements and design specifications outlined in the SRS. Key components of this plan include:

\begin{itemize}
    \item \textbf{Unit Testing:} A comprehensive suite of unit tests, as detailed in the project's test plan, will validate individual components or modules of the software. /textit{PyTest}, a flexible and powerful testing tool, will be used for writing and executing these tests.
    \item \textbf{Static Analysis:} /textit{Pylint} and /textit{Flake8} will be employed for static code analysis to identify potential bugs, security vulnerabilities, and issues with code style and complexity.
    \item \textbf{Code Reviews and Walkthroughs:} Regularly scheduled code reviews and walkthroughs with team members and supervisors to inspect code quality, readability, and adherence to the Flask framework's best practices and design patterns.
    \item \textbf{Continuous Integration:} Automated build and testing processes will be implemented using tools like GitHub Actions, to ensure continuous code quality, integration, and deployment.
    \item \textbf{Performance Testing:} The use of tools like Locust for load testing will help evaluate the application's performance under various conditions, particularly focusing on how the Flask application handles concurrent requests and data processing.
\end{itemize}

\subsection{Automated Testing and Verification Tools}

For automated testing and verification in our Flask/Python project, the following tools will be employed:

\begin{itemize}
    \item \textbf{Unit Testing Framework:} /textit{PyTest} will be used for developing and running unit tests.
    \item \textbf{Profiling and Performance Tools:} Tools like /textit{cProfile} for Python will assist in identifying performance bottlenecks and optimizing code efficiency.
    \item \textbf{Static Code Analyzers:} /textit{Pylint} and /textit{Flake8} will be used to analyze Python code quality, adherence to coding standards, and identification of potential errors.
    \item \textbf{Continuous Integration:} GitHub Actions will automate the build, testing, and deployment process, ensuring continuous integration and delivery of the Python codebase.
    \item \textbf{Linters:} /textit{Flake8} will be used to enforce coding standards.
\end{itemize}


\subsection{Software Validation Plan}

The Software Validation Plan will focus on ensuring that the final product meets the requirements and expectations of the stakeholders. Key strategies include:

\begin{itemize}
    \item \textbf{Beta Testing:} Involvement of selected users in the beta testing phase to provide real-world feedback on the software's functionality and usability.
    \item \textbf{Stakeholder Review Sessions:} Regular review meetings with stakeholders to confirm that the software meets the intended requirements and use cases.
    \item \textbf{Demo to Supervisor:} A demonstration of the software to the project supervisor following the Rev 0 demo for feedback and validation.
    \item \textbf{Reference to SRS Verification:} Aligning the validation activities with the SRS verification efforts to ensure consistency in meeting the documented requirements.
\end{itemize}

\section{System Test Description}
	
\subsection{Tests for Functional Requirements}

\begin{enumerate}
\item{TFR1-EXTRACT1\\}\label{TFR1-EXTRACT1}

Type: Functional, Manual, Dynamic

Initial State: User is logged into the system and on the course information extraction page.

Input/Condition: User uploads their course syllabi in PDF format.

Output/Result: The system extracts key details such as professor's email addresses, assignment weightings, and MSAF policy, displaying them to the user.

How test will be performed: A user uploads multiple course syllabi PDFs, and the system's ability to accurately extract and display the specified information is evaluated.

\item{TFR2-TASK1\\}\label{TFR2-TASK1}

Type: Functional, Manual, Dynamic
Initial State: The system has successfully extracted course information from an uploaded course outline.

Input/Condition: Course information is processed by the system.

Output/Result: Tasks are automatically created and added to the user's to-do list based on the extracted course information.

How test will be performed: Course outlines are uploaded, and the automatic generation of tasks in the to-do list is verified for correctness and completeness.

\item{TFR3-ADD1\\}\label{TFR3-ADD1}

Type: Functional, Manual, Dynamic

Initial State: User is on the course addition page.

Input/Condition: User inputs a valid course code to add a new course.

Output/Result: The course is successfully added to the user's profile.

How test will be performed: Users attempt to add various courses by providing valid course codes, and the system's response to correctly add those courses is assessed.

\item{TFR4-REMOVE1\\}\label{TFR4-REMOVE1}

Type: Functional, Manual, Dynamic

Initial State: User's profile contains one or more courses.

Input/Condition: User selects a course to remove from their profile.

Output/Result: The selected course is removed from the user's profile.

How test will be performed: A user with multiple courses on their profile attempts to remove one, and the successful removal and profile update are verified.

\item{TFR5-POMODORO1\\}\label{TFR5-POMODORO1}

Type: Functional, Manual, Dynamic

Initial State: User is on the Pomodoro timer page.

Input/Condition: User initiates a study session using the Pomodoro timer.

Output/Result: A Pomodoro study session starts.

How test will be performed: The user navigates to the Pomodoro page and starts a study session, verifying the timer's functionality and session tracking.

\item{TFR6-POMODORO2\\}\label{TFR6-POMODORO2}

Type: Functional, Manual, Dynamic

Initial State: User's to-do list contains at least one task.

Input/Condition: User starts a Pomodoro timer by selecting a specific task from the to-do list.
Output/Result: A Pomodoro study session specific to the selected task begins.

How test will be performed: The user selects a task from their to-do list to start a Pomodoro session, and the system's ability to associate the session with the selected task is evaluated.

\item{TFR7-MUSIC1\\}\label{TFR7-MUSIC1}

Type: Functional, Manual, Dynamic

Initial State: A Pomodoro study session is active.

Input/Condition: User selects to play background music during the study session.

Output/Result: Chosen background music plays during the Pomodoro session.

How test will be performed: During an active Pomodoro session, the user selects different music options to play in the background, and the system's ability to play and manage music selection is assessed.

\item{TFR8-TOMATO1\\}\label{TFR8-TOMATO1}

Type: Functional, Manual, Dynamic

Initial State: A Pomodoro study session has just been completed.

Input/Condition: Completion of a Pomodoro study session.

Output/Result: A tomato icon is generated and displayed in the user's "harvest bucket".

How test will be performed: After completing a Pomodoro session, the presence of a new tomato icon in the harvest bucket is verified to assess the system's reward mechanism.

\item{TFR9-TODO11\\}\label{TFR9-TODO1}

Type: Functional, Manual, Dynamic

Initial State: User is on the to-do list page.
Input/Condition: User adds a new task to the to-do list.

Output/Result: The new task appears on the to-do list.

How test will be performed: User attempts to add a task by specifying task details, and the addition of the task to the list is confirmed.

\item{TFR10-TODO2\\}\label{TFR10-TODO2}
Type: Functional, Manual, Dynamic

Initial State: User's to-do list contains at least one task.

Input/Condition: User selects a task to view its details.

Output/Result: Details of the selected task are displayed, including due date, associated course, weight, and other relevant information.

How test will be performed: User clicks on various tasks to view their details, verifying that all relevant information is accurately presented.


\item{TFR11-TODO3\\}\label{TFR11-TODO3}
Type: Functional, Manual, Dynamic

Initial State: User's to-do list contains at least one task.

Input/Condition: User selects an existing task to edit in the to-do list.

Output/Result: The task is updated with new information as provided by the user.

How test will be performed: User edits multiple tasks with different pieces of information, confirming that each change is reflected in the to-do list.


\item{TFR12-TODO4\\}\label{TFR12-TODO4}

Type: Functional, Manual, Dynamic

Initial State: User's to-do list contains several tasks.

Input/Condition: User views the to-do list.

Output/Result: Tasks are organized and displayed in three separate columns: To Do, In Progress, and Done.

How test will be performed: User verifies the organization of tasks into the specified columns and assesses the ease of understanding the task's status.


\item{TFR13-TODO5\\}\label{TFR13-TODO5}

Type: Functional, Manual, Dynamic

Initial State: User is on the to-do list page.

Input/Condition: User toggles between Kanban-style and calendar layout views.

Output/Result: The to-do list is displayed according to the selected layout preference.

How test will be performed: User switches between the two layout options multiple times to ensure the layout changes are applied correctly and persistently.


\item{TFR14-FORUM1\\}\label{TFR14-FORUM1}

Type: Functional, Manual, Dynamic

Initial State: User is on the forum page.

Input/Condition: User creates a new discussion topic.

Output/Result: The new topic is successfully created and visible in the forum.

How test will be performed: User attempts to create multiple discussion topics with different themes, verifying that each is added to the forum.

\item{TFR15-FORUM2\\}\label{TFR15-FORUM2}

Type: Functional, Manual, Dynamic

Initial State: Forum contains multiple discussion topics.

Input/Condition: User searches for a topic using keywords.

Output/Result: Topics matching the keywords are displayed to the user.

How test will be performed: User performs several searches using different keywords, and the accuracy and relevance of search results are evaluated.


\item{TFR15-FORUM3\\}\label{TFR16-FORUM3}

Type: Functional, Manual, Dynamic

Initial State: User is viewing a specific discussion topic in the forum.

Input/Condition: User submits a comment on the topic.

Output/Result: The comment is added to the discussion.

How test will be performed: User comments on various topics and verifies that their comments are correctly posted and visible to others.

\item{TFR17-FORUM4\\}\label{TFR17-FORUM4}

Type: Functional, Manual, Dynamic

Initial State: User is viewing a comment within a discussion topic in the forum.

Input/Condition: User replies to a comment.
Output/Result: The reply is posted as part of the discussion thread.

How test will be performed: User replies to multiple comments in different discussion threads, checking for the proper organization and visibility of their replies.

\item{TFR18-QUICKLINKS1\\}\label{TFR18-QUICKLINKS1}

Type: Functional, Manual, Dynamic

Initial State: User is on the dashboard or home page.

Input/Condition: User navigates to the quick links section.

Output/Result: The system displays key university websites and other relevant tools.

How test will be performed: User checks the quick links section for accessibility and relevance of the provided links to university websites and other educational tools.


\item{TFR19-QUICKLINKS2\\}\label{TFR19-QUICKLINKS2}

Type: Functional, Manual, Dynamic

Initial State: Quick links are displayed on the user's dashboard or home page.

Input/Condition: User attempts to drag and rearrange the order of website links.

Output/Result: The order of the links changes according to the user's customization.

How test will be performed: User rearranges the quick links in a new order, verifies the order is saved and persists across sessions.

\item{TFR20-FEEDBACK1\\}\label{TFR20-FEEDBACK1}

Type: Functional, Manual, Dynamic

Initial State: User is logged in and on the feedback submission page.

Input/Condition: User submits feedback through the feedback form.

Output/Result: Feedback is successfully submitted to the developers.

How test will be performed: User fills out and submits the feedback form with various types of feedback, confirming submission success and receipt by the development team.


\item{TFR21-FEEDBACK2\\}\label{TFR21-FEEDBACK2}

Type: Functional, Manual, Dynamic

Initial State: User has previously submitted feedback.

Input/Condition: User navigates to the feedback history page.

Output/Result: The system displays all past feedback submitted by the user.

How test will be performed: User reviews their feedback history to ensure all previously submitted feedback is visible and accurate.

\item{TFR22-FEEDBACK3\\}\label{TFR22-FEEDBACK3}

Type: Functional, Manual, Dynamic

Initial State: User has submitted feedback and is on the feedback status page.

Input/Condition: User checks the status of their submitted feedback.

Output/Result: The system shows the current status of each piece of feedback submitted by the user.

How test will be performed: User submits feedback and later checks the status of their submissions, verifying that the system accurately tracks and displays the status.

\item{TFR23-PROFILE1\\}\label{TFR23-PROFILE1}

Type: Functional, Manual, Dynamic

Initial State: User is on their profile settings page.

Input/Condition: User attempts to change their username.

Output/Result: The system updates the user's username across the platform.

How test will be performed: User changes their username in profile settings, then navigates the platform to ensure the new username is displayed and used consistently.

\item{TFR24-GPA1\\}\label{TFR24-GPA1}

Type: Functional, Manual, Dynamic

Initial State: User is on the GPA calculation page.

Input/Condition: User inputs their grades and credit hours to calculate their cumulated GPA.

Output/Result: The system calculates and displays the user's cumulated GPA.

How test will be performed: User enters a variety of grades and credit hours to calculate their GPA, checking for accuracy of the calculated GPA against manual calculations.


\subsection{Tests for Nonfunctional Requirements}

\subsubsection{Look and feel}
		

\begin{enumerate}

\item{TAR-1\\}\label{TAR-1}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to read the text on each page.
					
Output/Result:  \hyperref[MIN_UNDERSTAND]{\texttt{MIN\_UNDERSTAND\%}} of users reporting that all the texts are legible.
					
How test will be performed: The web application displayed with screens with various resolutions and sizes. \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to read the texts and report any unclear typography.
					
\item{TAR-2\\}\label{TAR-2}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to observe color on each page.
					
Output/Result: \hyperref[MIN_UNDERSTAND]{\texttt{MIN\_UNDERSTAND\%}} of users comfortable with the color used.
					
How test will be performed: \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to observe the color and report any distracting or overwhelming color palette.

\item{TAR-3\\}\label{TAR-3}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to interpret icons and graphics on each page.
					
Output/Result: \hyperref[MIN_UNDERSTAND]{\texttt{MIN\_UNDERSTAND\%}} of users able to understand the meaning of each icon and graphic as designed.
					
How test will be performed: \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked what they think each icon and graphic means. Any mismatch from the UI designer's intention would be recorded.

\item{TAR-4\\}\label{TAR-4}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to observe the layout of each page.
					
Output/Result: \hyperref[MIN_UNDERSTAND]{\texttt{MIN\_UNDERSTAND\%}} of users comfortable with the payout.
					
How test will be performed: The web application is launched with different devices including smartphones, tablets, and desktops.  \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to point out any unresponsive, out-of-margin, or compressed elements.

\item{TSTR-1\\}\label{TSTR-1}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to point out the menus and navigation bars.
					
Output/Result: \hyperref[MIN_UNDERSTAND]{\texttt{MIN\_UNDERSTAND\%}} of users able to locate menus and navigation tools without confusion.
					
How test will be performed: \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to point out the menus and navigation bars without assistance.

\item{TSTR-2\\}\label{TSTR-2}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to point out inconsistent UI elements.
					
Output/Result: \hyperref[MAX_ELEMENT_BAD]{\texttt{MAX\_ELEMENT\_BAD}} inconsistent UI elements found.
					
How test will be performed: \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to explore the application and point out any inconsistent UI elements that break the harmony.

\item{TSTR-3\\}\label{TSTR-3}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to click each interactive UI element.
					
Output/Result: \hyperref[MAX_ELEMENT_BAD]{\texttt{MAX\_ELEMENT\_BAD}} interactive UI elements being unresponsive.
					
How test will be performed: \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to explore the application and report any unresponsive interactive elements.

\item{TSTR-4\\}\label{TSTR-4}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to adjust font size.
					
Output/Result: \hyperref[MAX_UNSATISFIED]{\texttt{MAX\_UNSATISFIED\%}} of users reporting unsuitable font size.
					
How test will be performed: \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to report how they like the default font size and attempt to adjust the font size to their preference. Report if the adjusted font still causes difficulty in reading.

\item{TSTR-5\\}\label{TSTR-5}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to perform a task while an animation is displayed.
					
Output/Result: \hyperref[MIN_UNDERSTAND]{\texttt{MIN\_UNDERSTAND\%}} of users who could perform the task distracted.
					
How test will be performed: \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to perform a task that involves the animation display part of the screen.  They are asked to report if they feel the animation is intrusive or distracting.
\end{enumerate}

\subsubsection{Usability and Humanity}

\begin{enumerate}
\item{TUHR-1\\}\label{TUHR-1}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to navigate to a required page.
					
Output/Result: \hyperref[MIN_UNDERSTAND]{\texttt{MIN\_UNDERSTAND\%}} of users able to navigate to a required page without confusion.
					
How test will be performed: In an obeservational study, \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to navigate to a required page without assistance within a reasonable amount of time undergoing minimum trial and error.

\item{TUHR-2\\}\label{TUHR-2}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to perform a core function.
					
Output/Result: \hyperref[MIN_UNDERSTAND]{\texttt{MIN\_UNDERSTAND\%}} of users able to perform a core function.
					
How the test will be performed: In an obeservational study,\hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to perform a core function within a reasonable amount of time undergoing minimum trial and error.
\item{TUHR-3\\}\label{TUHR-3}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to inspect the grammar of texts on the page.
					
Output/Result: \hyperref[MAX_BAD_GRAMMAR]{\texttt{MAX\_BAD\_GRAMMAR}} grammar mistakes found.
					
How test will be performed: In an obeservational study, \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to report grammar mistakes in all the text visible in this web application.

\item{TUHR-4\\}\label{TUHR-4}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to inspect for offensive messages on the page.
					
Output/Result: \hyperref[MAX_OFFENSIVE]{\texttt{MAX\_OFFENSIVE}} offensive messages found.
					
How test will be performed: In an obeservational study, \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to report offensive messages in all the text visible in this web application.

\item{TUHR-5\\}\label{TUHR-5}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to observe color combinations on the page.
					
Output/Result: \hyperref[MAX_COLOR_AMBIGUOUS]{\texttt{MAX\_COLOR\_AMBIGUOUS}} indistinguishable color combinations found.
					
How test will be performed: In an obeservational study, \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to report indistinguishable color combinations in this web application. This user group should include people with color blindness.


\end{enumerate}

\subsubsection{Performance}

\begin{enumerate}
\item{TSLR-1\\}\label{TSLR-1}

Type: Dynamic, Automatic
					
Initial State: The web application is launched.
					
Input/Condition: The processing time for a core function.
					
Output/Result: It takes \hyperref[MAX_TIME_PROCESS]{\texttt{MAX\_TIME\_PROCESS}} for the application to finish a core function.
					
How test will be performed: An automated script is used to perform and time a core function, including uploading syllabuses, generating tasks, and prioritizing tasks.

\end{enumerate}
\subsubsection{Safety-Critical}

\begin{enumerate}
\item{TSCR-1\\}\label{TSCR-1}

Type: Dynamic, Automatic
					
Initial State: The web application is launched.
					
Input/Condition: A pair of new credentials are added.
					
Output/Result: Format of credentials in database.
					
How test will be performed: An automated script is used to add a pair of new credentials and check whether plain text is stored in the database.

\end{enumerate}
\subsubsection{Precision and Accuracy}

\begin{enumerate}
\item{TPAR-1\\}\label{TPAR-1}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition:  Course outlines in PDF are uploaded
					
Output/Result: \hyperref[MIN_PRECISION]{\texttt{MIN\_PRECISION\%}} of coincidence between algorithm result and human result.
					
How test will be performed: A manual test is performed by one of our developers to upload multiple course outlines and manually record the percentage of course information that are correctly extracted. 

\end{enumerate}

\subsubsection{Robustness and Fault-Tolerance}

\begin{enumerate}
\item{TRFTR-1\\}\label{TRFTR-1}

Type: Dynamic, Automated
					
Initial State: The web application is launched.
					
Input/Condition: Incorrect user input.
					
Output/Result: \hyperref[MIN_OPERABLE]{\texttt{MIN\_OPERABLE\%}} of the system operating.
					
How test will be performed: An automated script is used to put false input in every interactive element, including wrong file format, special characters, out-of-boundary data, and malicious commands.
\end{enumerate}
\subsubsection{Capacity}

\begin{enumerate}

\item{TCR-1\\}\label{TCR-2}

Type: Dynamic, Automated
					
Initial State: The web application is launched.
					
Input/Condition: Massive course data input.
					
Output/Result: It takes \hyperref[MAX_TIME_PROCESS]{\texttt{MAX\_TIME\_PROCESS}} to finish a core function.
					
How test will be performed: An automated script is used to inject a large amount of course data.  Run TSLR-5.

\end{enumerate}

\subsubsection{Operational  and Environmental}

\begin{enumerate}
\item{TOER-1\\}\label{TOER-1}

Type: Dynamic, Automated
					
Initial State: The web application is launched.
					
Input/Condition: Send requests to supported calendar APIs.
					
Output/Result: \hyperref[MIN_API_SUCCESS]{\texttt{MIN\_API\_SUCCESS\%}} of successful API requests.
					
How test will be performed: An automated script is used to send requests to calendar APIs and record the result.


\item{TOER-2\\}\label{TOER-2}

Type: Dynamic, Automated
					
Initial State: The web application is launched.
					
Input/Condition: Run regression test suites.
					
Output/Result: \hyperref[MIN_REGRESSION_PASS]{\texttt{MIN\_REGRESSION\_PASS\%}} of passed regression tests.
					
How test will be performed: An automated script is used to run regression tests.

\end{enumerate}
\subsubsection{Maintainability and Support}

\begin{enumerate}
\item{TSPR-1\\}\label{TSPR-1}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to contact support.
					
Output/Result: \hyperref[MAX_SUPPORT_STEP]{\texttt{MAX\_SUPPORT\_STEP}} steps needed to reach help.
					
How test will be performed: \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to reach the helpdesk through email, phone, and chatbot and record the steps it takes from the main page to help.


\item{TSPR-2\\}\label{TSPR-2}

Type: Dynamic, Automatic
					
Initial State: The web application is launched.
					
Input/Condition: User feedback is inputted.
					
Output/Result: User input in database.
					
How test will be performed: A script is used to input user feedback and check if this feedback gets stored in the database.

\end{enumerate}

\subsubsection{Security}

\begin{enumerate}

\item{TSR-1\\}\label{TSR-3}

Type: Dynamic, Manual
					
Initial State: The web application is launched.
					
Input/Condition: Users are asked to modify the database.
					
Output/Result: \hyperref[MAX_ATTACK_SUCCESS]{\texttt{MAX\_ATTACK\_SUCCESS}} users successfully modified the database.
					
How test will be performed: \hyperref[MIN_TESTER_NUM]{\texttt{MIN\_TESTER\_NUM}} users are asked to taint the database as unauthorised entity.

\item{TSR-2\\}\label{TSR-4}

Type: Dynamic, Automatic
					
Initial State: The web application is launched.
					
Input/Condition: A series of user actions.
					
Output/Result: An audit log.
					
How test will be performed: A script is used to perform a series of user actions and check that the activities are recorded with time stamps and relevant meta-data.

\end{enumerate}

\subsubsection{Complience}

\begin{enumerate}
\item{TCPR-1\\}\label{TCPR-1}

Type: Dynamic, Manual
					
Initial State: Development container is launched.
					
Input/Condition: A PR containing local changes is pushed.
					
Output/Result: Workflow result.
					
How test will be performed: A PR containing local changes is pushed, which triggers a workflow linter check.
\end{enumerate}
\subsection{Traceability Between Test Cases and Requirements}
All requirements refer to \href{https://github.com/wangq131/4G06CapstoneProjectT5/blob/689841fefc298f80d84232996e1c7ca7981dd93d/docs/SRS/SRS.pdf}{SRS.pdf}.


\clearpage
\begin{table}
    \centering
    \begin{adjustbox}{width=1.2\textwidth}
    \begin{tabular}{l|ccccccccccccccccccccccccc}
        \textbf{Test Case \#} & \multicolumn{15}{c}{\textbf{Requirement \#}}\\
        \hline
        ~ & \textbf{AR1} & \textbf{AR2} & \textbf{AR3} & \textbf{AR4} & \textbf{STR1} & \textbf{STR2} & \textbf{STR3} & \textbf{STR4}& \textbf{STR5} & \textbf{UHR1} & \textbf{UHR2} & \textbf{UHR3} & \textbf{UHR4} & \textbf{UHR5}& \textbf{SLR1}& \textbf{SCR1}& \textbf{PAR1}& \textbf{RFTR1}& \textbf{CR1}& \textbf{CR2}& \textbf{SER1}& \textbf{OER1}& \textbf{OER2}& \textbf{OER3}\\\
        \hyperref[TAR-1]{\textbf{TAR-1}}  & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TAR-2]{\textbf{TAR-2}}    & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TAR-3]{\textbf{TAR-3}}  & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TAR-4]{\textbf{TAR-4}}  & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TSTR-1]{\textbf{TSTR-1}}  & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TSTR-2]{\textbf{TSTR-2}}  & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TSTR-3]{\textbf{TSTR-3}}  & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TSTR-4]{\textbf{TSTR-4}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TSTR-5]{\textbf{TSTR-5}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TUHR-1]{\textbf{TUHR-1}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TUHR-2]{\textbf{TUHR-2}}    & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TUHR-3]{\textbf{TUHR-3}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TUHR-4]{\textbf{TUHR-4}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TUHR-5]{\textbf{TUHR-5}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TSLR-1]{\textbf{TSLR-1}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TSCR-1]{\textbf{TSCR-1}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TPAR-1]{\textbf{TPAR-1}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TRFTR-1]{\textbf{TRFTR-1}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~ & ~ & ~\\
        \hyperref[TCR-2]{\textbf{TCR-2}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~ & ~ & ~\\
        \hyperref[TOER-1]{\textbf{TOER-1}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & X & ~\\
        \hyperref[TOER-2]{\textbf{TOER-2}}  & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ &  & X\\
    \end{tabular}
    \end{adjustbox}
    \caption{Traceability Matrix: Test Cases to Non-Functional Requirements}
\end{table}

\begin{table}[ht]
    \centering
    \begin{adjustbox}{width=1.2\textwidth}
    \small % Adjust font size as needed
    \begin{tabular}{l|ccccccccccccccccccccccccc}
        \textbf{Test Case \#} & \multicolumn{24}{c}{\textbf{Requirement \#}}\\
        \hline
        ~ & \textbf{FR1} & \textbf{FR2} & \textbf{FR3} & \textbf{FR4} & \textbf{FR5} & \textbf{FR6} & \textbf{FR7} & \textbf{FR8} & \textbf{FR9} & \textbf{FR10} & \textbf{FR11} & \textbf{FR12} & \textbf{FR13} & \textbf{FR14} & \textbf{FR15} & \textbf{FR16} & \textbf{FR17} & \textbf{FR18} & \textbf{FR19} & \textbf{FR20} & \textbf{FR21} & \textbf{FR22} & \textbf{FR23} & \textbf{FR24} \\
        \hline
        \hyperref[TFR1-EXTRACT1]{\textbf{TFR1-EXTRACT1}} & X & & & & & & & & & & & & & & & & & & & & & & & \\
        \hyperref[TFR2-TASK1]{\textbf{TFR2-TASK1}} & & X & & & & & & & & & & & & & & & & & & & & & & \\
        \hyperref[TFR3-ADD1]{\textbf{TFR3-ADD1}} & & & X & & & & & & & & & & & & & & & & & & & & & \\
        \hyperref[TFR4-REMOVE1]{\textbf{TFR4-REMOVE1}} & & & & X & & & & & & & & & & & & & & & & & & & & \\
        \hyperref[TFR5-POMODORO1]{\textbf{TFR5-POMODORO1}} & & & & & X & & & & & & & & & & & & & & & & & & & \\
        \hyperref[TFR6-POMODORO2]{\textbf{TFR6-POMODORO2}} & & & & & & X & & & & & & & & & & & & & & & & & & \\
        \hyperref[TFR7-MUSIC1]{\textbf{TFR7-MUSIC1}} & & & & & & & X & & & & & & & & & & & & & & & & & \\
        \hyperref[TFR8-TOMATO1]{\textbf{TFR8-TOMATO1}} & & & & & & & & X & & & & & & & & & & & & & & & & \\
        \hyperref[TFR9-TODO1]{\textbf{TFR9-TODO1}} & & & & & & & & & X & & & & & & & & & & & & & & & \\
        \hyperref[TFR10-TODO2]{\textbf{TFR10-TODO2}} & & & & & & & & & & X & & & & & & & & & & & & & & \\
        \hyperref[TFR11-TODO3]{\textbf{TFR11-TODO3}} & & & & & & & & & & & X & & & & & & & & & & & & & \\
        \hyperref[TFR12-TODO4]{\textbf{TFR12-TODO4}} & & & & & & & & & & & & X & & & & & & & & & & & & \\
        \hyperref[TFR13-TODO5]{\textbf{TFR13-TODO5}} & & & & & & & & & & & & & X & & & & & & & & & & & \\
         \hyperref[TFR14-FORUM1]{\textbf{TFR14-FORUM1}} & & & & & & & & & & & & & & X & & & & & & & & & & \\
        \hyperref[TFR15-FORUM2]{\textbf{TFR15-FORUM2}} & & & & & & & & & & & & & & & X & & & & & & & & & \\
        \hyperref[TFR16-FORUM3]{\textbf{TFR16-FORUM3}} & & & & & & & & & & & & & & & & X & & & & & & & & \\
        \hyperref[TFR17-FORUM4]{\textbf{TFR17-FORUM4}} & & & & & & & & & & & & & & & & & X & & & & & & & \\
        \hyperref[TFR18-QUICKLINKS1]{\textbf{TFR18-QUICKLINKS1}} & & & & & & & & & & & & & & & & & & X & & & & & & \\
        \hyperref[TFR19-QUICKLINKS2]{\textbf{TFR19-QUICKLINKS2}} & & & & & & & & & & & & & & & & & & & X & & & & & \\
        \hyperref[TFR20-FEEDBACK1]{\textbf{TFR20-FEEDBACK1}} & & & & & & & & & & & & & & & & & & & & X & & & & \\
        \hyperref[TFR21-FEEDBACK2]{\textbf{TFR21-FEEDBACK2}} & & & & & & & & & & & & & & & & & & & & & X & & & \\
        \hyperref[TFR22-FEEDBACK3]{\textbf{TFR22-FEEDBACK3}} & & & & & & & & & & & & & & & & & & & & & & X & & \\
        \hyperref[TFR23-PROFILE1]{\textbf{TFR23-PROFILE1}} & & & & & & & & & & & & & & & & & & & & & & & X & \\
        \hyperref[TFR24-GPA1]{\textbf{TFR24-GPA1}} & & & & & & & & & & & & & & & & & & & & & & & & X \\
\hline
\end{tabular}
\end{adjustbox}
\caption{Traceability Matrix: Test Cases to Functional Requirements}
\end{table}




\pagestyle{plain}%
\clearpage

				
% \bibliographystyle{plainnat}
\section{Unit Test Description}

\subsection{Unit Testing Scope}
Unit testing will focus on individual units or components of the software to determine if they operate correctly. Each test case is designed based on a functional requirement from the SRS.


\subsection{Tests for Functional Requirements}

\section{Functional Requirements Evaluation}

This section outlines our approach for the unit testing of the functional requirements specified in our Software Requirements Specification (SRS) document. These tests are aimed at verifying that each component of the system behaves as intended.

\subsection{Unit Testing Plan}

Unit testing will focus on individual units or components of the software to determine if they operate correctly. Each test case is designed based on a functional requirement from the SRS.

\subsection{Tests for Functional Requirements}

\begin{enumerate}
    
    \item{UT-1\\}\label{UT-1}
    
        Objective: To verify that the system correctly extracts and displays key course information from uploaded syllabi.
        
        Input: User uploads a course syllabus in PDF format.
        
        Expected Output: Key details such as professor's email addresses, assignment weightings, and MSAF policy are extracted and displayed to the user.
        
        Requirement Reference: FR1 - Course Information Extraction.
        
    \item{UT-2\\}\label{UT-2}
    
        Objective: To verify the system automatically creates tasks from extracted course information and adds them to the user's to-do list.
        
        Input: Course information is processed by the system after a syllabus upload.
        
        Expected Output: Tasks are automatically created and added to the user's to-do list based on the extracted course information.
        
        Requirement Reference: FR2 - Task Creation from Course Information.
        
    \item{UT-3\\}\label{UT-3}
    
        Objective: To verify that users can successfully add a new course by providing a valid course code.
        
        Input: User inputs a valid course code to add a new course.
        
        Expected Output: The new course is added to the user's profile.
        
        Requirement Reference: FR3 - Add New Course.
        
    \item{UT-4\\}\label{UT-4}
    
        Objective: To verify that users can remove a course from their profile.
        
        Input: User selects a course to remove from their profile.
        
        Expected Output: The selected course is removed from the user's profile.
        
        Requirement Reference: FR4 - Remove Course.
        
    \item{UT-5\\}\label{UT-5}
    
        Objective: To verify that the system allows users to start a study session using the Pomodoro timer.
        
        Input: User initiates a Pomodoro timer on the Pomodoro page.
        
        Expected Output: A Pomodoro study session starts and is tracked by the system.
        
        Requirement Reference: FR5 - Pomodoro Timer Start from Page.
        
    \item{UT-6\\}\label{UT-6}
    
        Objective: To verify that users can start a Pomodoro study session by selecting a specific task from the to-do list.
        
        Input: User starts a Pomodoro timer by clicking a specific task in their to-do list.
        
        Expected Output: A Pomodoro study session specific to the selected task begins.
        
        Requirement Reference: FR6 - Pomodoro Timer Start from Task.
        
    \item{UT-7\\}\label{UT-7}
    
        Objective: To verify that users can select and play different music as background during their study session.
        
        Input: User selects a music option to play during an active Pomodoro study session.
        
        Expected Output: The selected music plays in the background during the study session.
        
        Requirement Reference: FR7 - Music Selection for Pomodoro Session.
        
    \item{UT-8\\}\label{UT-8}
    
        Objective: To verify the system generates and displays a tomato icon in the harvest bucket upon completion of a study session.
        
        Input: Completion of a Pomodoro study session.
        
        Expected Output: A tomato icon is generated and displayed in the user's harvest bucket.
        
        Requirement Reference: FR8 - Tomato Harvesting Post Study Session.
        
    \item{UT-9\\}\label{UT-9}
    
        Objective: To verify that users can add a task to their to-do list successfully.
        
        Input: User adds a new task with details to their to-do list.
        
        Expected Output: The new task is visible on the to-do list with the specified details.
        
        Requirement Reference: FR9 - Adding a Task to the To-Do List.
        
    \item{UT-10\\}\label{UT-10}
    
        Objective: To verify that users can view details of a task including due date, associated course, and weight.
        
        Input: User selects a task to view its details.
        
        Expected Output: Detailed information about the task is displayed to the user.
        
        Requirement Reference: FR10 - Task Detail Viewing.
        
    \item{UT-11\\}\label{UT-11}
    
        Objective: To verify that users can edit an existing task in their to-do list.
        
        Input: User edits an existing task by changing its details.
        
        Expected Output: The task is updated with the new information provided by the user.
        
        Requirement Reference: FR11 - Editing an Existing Task.
        
    \item{UT-12\\}\label{UT-12}
    
        Objective: To verify that tasks are organized into 'To Do', 'In Progress', and 'Done' columns.
        
        Input: Viewing the to-do list with multiple tasks in different stages.
        
        Expected Output: Tasks are correctly organized and displayed in their respective columns.
        
        Requirement Reference: FR12 - Task Organization in Columns.

    \item{UT-13\\}\label{UT-13}
    
        Objective: To verify the functionality of creating a new topic in the forum for discussion.
        
        Input: User submits a new discussion topic with title and description.
        
        Expected Output: The new topic is successfully created and visible in the forum.
        
        Requirement Reference: FR14 - Forum Topic Creation.
        
    \item{UT-14\\}\label{UT-14}
    
        Objective: To verify that users can search for topics in the forum using keywords.
        
        Input: User enters keywords in the forum search field.
        
        Expected Output: Topics matching the keywords are displayed to the user.
        
        Requirement Reference: FR15 - Forum Topic Search.
        
    \item{UT-15\\}\label{UT-15}
    
        Objective: To verify that users can comment on a specific topic in the forum.
        
        Input: User submits a comment on a forum topic.
        
        Expected Output: The comment is added to the discussion under the topic.
        
        Requirement Reference: FR16 - Forum Topic Commenting.
        
    \item{UT-16\\}\label{UT-16}
    
        Objective: To verify that users can reply to a comment within a forum topic.
        
        Input: User submits a reply to an existing comment.
        
        Expected Output: The reply is correctly threaded under the original comment.
        
        Requirement Reference: FR17 - Comment Replies in Forum.
        
    \item{UT-17\\}\label{UT-17}
    
        Objective: To verify that users can access key university websites and other relevant tools from the quick links section.
        
        Input: User navigates to the quick links section on the dashboard.
        
        Expected Output: Key university websites and other relevant tools are displayed and accessible.
        
        Requirement Reference: FR18 - Quick Links Access.
        
    \item{UT-18\\}\label{UT-18}
    
        Objective: To verify that users can customize the order of website links in the quick links section.
        
        Input: User drags and rearranges the order of quick links.
        
        Expected Output: The order of the links changes and persists according to user customization.
        
        Requirement Reference: FR19 - Customizing Order of Quick Links.
        
    \item{UT-19\\}\label{UT-19}
    
        Objective: To verify that the system allows users to submit feedback through the feedback form.
        
        Input: User fills out and submits the feedback form.
        
        Expected Output: Feedback is successfully submitted and received by the system.
        
        Requirement Reference: FR20 - Feedback Submission.
        
    \item{UT-20\\}\label{UT-20}
    
        Objective: To verify that users can view their previously submitted feedback.
        
        Input: User navigates to the feedback history page.
        
        Expected Output: All past feedback submitted by the user is visible and accurately displayed.
        
        Requirement Reference: FR21 - Viewing Past Feedback.
        
    \item{UT-21\\}\label{UT-21}
    
        Objective: To verify that users can check the status of their submitted feedback.
        
        Input: User checks the status of submitted feedback in the feedback section.
        
        Expected Output: The current status of each submitted feedback is accurately displayed.
        
        Requirement Reference: FR22 - Checking Feedback Status.
        
    \item{UT-22\\}\label{UT-22}
    
        Objective: To verify that the system allows users to change their username through their profile settings.
        
        Input: User changes their username in the profile settings.
        
        Expected Output: The system updates the user's username across the platform.
        
        Requirement Reference: FR23 - Username Change.
        
    \item{UT-23\\}\label{UT-23}
    
        Objective: To verify that the system allows users to calculate their cumulative GPA by inputting grades and credit hours.
        
        Input: User inputs their grades and credit hours on the GPA calculation page.
        
        Expected Output: The system calculates and displays the user's cumulative GPA.
        
        Requirement Reference: FR24 - GPA Calculation.
\end{enumerate}

\subsection{Traceability Between Test Cases and Modules}
\begin{landscape}
\begin{table}[H]
    \centering
    \begin{adjustbox}{width=1.4\textwidth}
    \begin{tabular}{l|cccccccccccccccccccccccc}
        \hline
        \textbf{Test Case \#} & \textbf{FR1} & \textbf{FR2} & \textbf{FR3} & \textbf{FR4} & \textbf{FR5} & \textbf{FR6} & \textbf{FR7} & \textbf{FR8} & \textbf{FR9} & \textbf{FR10} & \textbf{FR11} & \textbf{FR12} & \textbf{FR13} & \textbf{FR14} & \textbf{FR15} & \textbf{FR16} & \textbf{FR17} & \textbf{FR18} & \textbf{FR19} & \textbf{FR20} & \textbf{FR21} & \textbf{FR22} & \textbf{FR23} & \textbf{FR24} \\
        \hline
        \hyperref[UT-1]{\textbf{UT-1}} & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-2]{\textbf{UT-2}} &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-3]{\textbf{UT-3}} &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-4]{\textbf{UT-4}} &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-5]{\textbf{UT-5}} &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-6]{\textbf{UT-6}} &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-7]{\textbf{UT-7}} &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-8]{\textbf{UT-8}} &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-9]{\textbf{UT-9}} &  &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-10]{\textbf{UT-10}} &  &  &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-11]{\textbf{UT-11}} &  &  &  &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-12]{\textbf{UT-12}} &  &  &  &  &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-13]{\textbf{UT-13}} &  &  &  &  &  &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-14]{\textbf{UT-14}} &  &  &  &  &  &  &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-15]{\textbf{UT-15}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  &  \\
        \hyperref[UT-16]{\textbf{UT-16}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  &  \\
        \hyperref[UT-17]{\textbf{UT-17}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & X &  &  &  &  &  &  &  \\
        \hyperref[UT-17]{\textbf{UT-18}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & & X  &  &  &  &  &  &  \\
        \hyperref[UT-17]{\textbf{UT-19}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & & & X  &  &  &  &  &  \\
        \hyperref[UT-17]{\textbf{UT-20}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & & &  &  X  &  &  &  &  \\
        \hyperref[UT-17]{\textbf{UT-21}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & & &  &  &  X  &  &  &  \\
        \hyperref[UT-17]{\textbf{UT-22}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & & &  &  &  &  X  &  &  \\
        \hyperref[UT-17]{\textbf{UT-23}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & & &  &  &  &  &  X  &  \\
        \hyperref[UT-17]{\textbf{UT-24}} &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & & &  &  &  &  &  &  X  \\
        % Add more \hyperref entries as needed for each test case and its corresponding FR
        \hline
    \end{tabular}
    \end{adjustbox}
    \caption{Traceability Matrix: Unit Test Cases to Functional Requirements}
\end{table}
\end{landscape}


\newpage

\section{Appendix}

This is where you can place additional information.

\subsection{Symbolic Parameters}

\begin{longtable}{|l|l|l|p{5cm}|}

\hline
parameter & value & unit & description\\
\hline
\texttt{MIN\_UNDERSTAND\%}\label{MIN_UNDERSTAND} & 90 & N/A & the minimum percentage of testers who can understand among all testers\\
\hline
\texttt{MAX\_UNSATISFIED\%}\label{MAX_UNSATISFIED} & 5 & N/A & the maximum percentage of testers reporting uncomfortable\\
\hline
\texttt{MAX\_TRIAL\_TIME}\label{MAX_TRIAL_TIME} & 1200 & \texttt{s} & the maximum allowed trial time\\
\hline
\texttt{MIN\_TESTER\_NUM}\label{MIN_TESTER_NUM} &  10 & N/A & the minimum number of testers needed\\
\hline
\texttt{MAX\_BAD\_GRAMMAR}\label{MAX_BAD_GRAMMAR} & 0 & N/A & the maximum occurrence of grammar mistakes allowed \\
\hline
\texttt{MAX\_OFFENSIVE}\label{MAX_OFFENSIVE} & 0& N/A & the maximum occurrence of offensive messages allowed\\
\hline
\texttt{MAX\_ELEMENT\_BAD}\label{MAX_ELEMENT_BAD} & 0& N/A & the maximum occurrence of inconsistent 
 or unresponsive elements allowed\\
\hline
\texttt{MAX\_ATTACK\_SUCCESS}\label{MAX_ATTACK_SUCCESS} & 0& N/A & the maximum occurrence of successful attack\\
\hline
\texttt{MAX\_COLOR\_AMBIGUOUS}\label{MAX_COLOR_AMBIGUOUS} & 0& N/A & the maximum occurrence of indistinguishable color combinations allowed\\
\hline
\texttt{MAX\_TIME\_PROCESS}\label{MAX_TIME_PROCESS} & 2& s & the maximum processing time for a core function\\
\hline
\texttt{MIN\_PRECISION\%}\label{MIN_PRECISION} & 90 & N/A & the minimum precision of the algorithm\\
\hline
\texttt{MIN\_OPERABLE\%}\label{MIN_OPERABLE} & 95 & N/A & the minimum percentage of system being operable \\
\hline
\texttt{MIN\_API\_SUCCESS\%}\label{MIN_API_SUCCESS} & 95 & N/A &  the minimum percentage of successful API calls\\
\hline
\texttt{MIN\_REGRESSION\_PASS\%}\label{MIN_REGRESSION_PASS} & 100  & N/A &  the minimum percentage of successful API calls\\
\hline
\texttt{MAX\_RESPONSE\_TIME}\label{MAX_RESPONSE_TIME} & 24 & h & The maximum issue resolve response time\\
\hline
\texttt{MIN\_LANGUAGE}\label{MIN_LANGUAGE} & 5& N/A & The minimum number of languages that can be translated\\
\hline
\texttt{MAX\_SUPPORT\_STEP}\label{MAX_SUPPORT_STEP} & 5&N/A& The maximum steps needed for asking for support\\

\hline
\end{longtable}

\subsection{Survey Questions}

\begin{enumerate}
  \item Are you a student? If so, are you from McMaster?
  \item Which following current feature in the website attracts you the most?
  \item Please select from the options below that you think may be used less often?
  \item We are considering adding some new features to the website to improve your experience. Please select from the options below the features that you think will make you use our site more frequently.
  \item Is the content on our website clear and understandable?
  \item On a scale of 1 to 5, how easy was it to navigate our website overall?
  \item On a scale of 1 to 5, how would you rate the ease of the priority generation feature?
  \item On a scale of 1 to 5, how visually appealing do you find our website?
  \item Were you able to find all the current features we have? if not, please describe the problem you met.
  \item On a scale of 1 to 5, how would you rate the accuracy of the information provided on our website overall?
  \item On a scale of 1 to 5, how would you rate the task priority feature?
  \item have you encountered any other inaccuracies while using our website? if yes, please provide examples.
\end{enumerate}

\newpage{}
\section*{Appendix --- Reflection}


The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\begin{enumerate}
  \item What knowledge and skills will the team collectively need to acquire to
  successfully complete the verification and validation of your project?
  Examples of possible knowledge and skills include dynamic testing knowledge,
  static testing knowledge, specific tool usage etc.  You should look to
  identify at least one item for each team member.


  \begin{itemize}
    \item UI/UX usability validation tools such  as \textit{UserTesting}, \textit{Lookback.io}. to better evaluate our product is user-friendly in a couple of perspectives: effective, learnable, and user-friendly.
    \item Dynamic Testing Tools such as \textit{Behave}, which is a tool that allows users to write the test cases in human languages to test for python-system framework. 
    \item AI Model Validation Frameworks such as \textit{Snitch AI} and \textit{scikit-learn} which can help our trained morel enhance quality and troubleshoot quickly.
    \item Static Code Analysis Tools such as \textit{SonarQube} to ensure the code quality which also can be integrated with \textit{CI/CD} for continuous development
    \item Enhance continuous delivery/deployment by exploring the \textit{Actions} features in \textit{GitHub} Pro to build custom workflow pipeline.
   \end{itemize} 


  \item For each of the knowledge areas and skills identified in the previous
  question, what are at least two approaches to acquiring the knowledge or
  mastering the skill?  Of the identified approaches, which will each team
  member pursue, and why did they make this choice?

  \begin{table}[]
    \begin{tabular}{| p{3cm} | p{3.5cm} | p{2cm} | p{5cm} |}
    \hline
      \textbf{Knowledge or Skills} & \textbf{Approaches} & \textbf{Assigned Team Member} & \textbf{Reason} \\
    \hline
      \raggedright UI/UX Usability validation & \raggedright Use \textit{ChatGPT}, \textit{Google}, watch online tutorials, or ask supervisor for help  & Shuting, Shi & Working on the initial UI design, familiar with the key features and the components of website. Therefore, can detect the usability requirements of our target user groups and easy to make modifications accordingly \\
    \hline
      \raggedright  Dynamic Testing Tools & \raggedright Use \textit{ChatGPT}, \textit{Google}, watch online tutorials & Qiang, Gao & Have the related experience in the previous co-op work terms, implemented similar functionality in previous project. Strong interest in the dynamic testing section. \\
    \hline
      \raggedright AI Model Validation Framework & \raggedright Use \textit{ChatGPT}, \textit{Google}, watch online tutorials & Qianni, Wang & Experience with many ML projects where these libraries are being used in AI programs and previous co-op work terms. Working on the model training,  data-sets selection and integration, familiar with the model algorithm, easy to do modifications if encounters specific model bias. \\
    \hline
      \raggedright Static Code Analysis Tools & \raggedright Use \textit{ChatGPT}, \textit{Google}, watch online tutorials & Chenwei, Song & Experience in enhancing clean code in previous co-op work terms. Strong interest in the code analysis section. \\
    \hline
      \raggedright GitHub Action Feature & \raggedright Use \textit{ChatGPT}, \textit{Google}, and watch online tutorials & Jingyao, Qin & Strong interest in GitHub features, have related experience in the previous coop term, quick to hand on this technique. \\
    \hline
    \end{tabular}
\end{table}
\end{enumerate}

\end{document}
